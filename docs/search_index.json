[["index.html", "1 Welcome to S2Y Lab 6 1.1 Introduction", " S2Y Lab 6 Interval estimation and hypothesis testing 1 Welcome to S2Y Lab 6 Intended Learning Outcomes: use various summary statistics and R output to compute confidence and prediction intervals; use R to produce hypothesis tests for parameters in a linear model; interpret hypothesis tests and confidence and prediction intervals. 1.1 Introduction In the lectures we learned about the general formulae for the construction of: a confidence interval for a linear combination of the model parameters (\\(\\mathbf{b}^\\top\\boldsymbol{\\beta}\\)) with confidence level \\(c\\) \\[\\mathbf{b}^\\top\\boldsymbol{\\hat{\\beta}}\\pm t\\left(n-p; \\frac{1+c}{2}\\right)\\sqrt{\\frac{\\text{RSS}}{n-p}\\mathbf{b}^\\top(\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{b}};\\] a prediction interval for a future value of the response variable for particular values of the predictor variables with confidence \\(c\\) \\[\\mathbf{b}^\\top\\boldsymbol{\\hat{\\beta}}\\pm t\\left(n-p; \\frac{1+c}{2}\\right)\\sqrt{\\frac{\\text{RSS}}{n-p}\\left(1+\\mathbf{b}^\\top(\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{b}\\right)}\\] In this practical, it will be demonstrated how these intervals can be computed using R. The emphasis will be on the computation, application and interpretation of confidence and prediction intervals. We will also consider hypothesis testing for parameters in a linear model. QUESTION: The figures below show the scatterplot of some observations (black circles), the best fitted line (black line), a 95% confidence interval (red dashed line), and a 95% prediction interval (blue dotted line). Which of the figures shows the correct relationship between confidence interval and prediction interval? A B C D Solution The correct answer is option (A). Here we use two properties of confidence interval and prediction interval: Confidence interval and prediction interval are centred at the same best fitting line. For the same confidence level, prediction interval is wider than confidence interval. In addition, looking at the figures, you may notice another property that the width of both interval is narrowest at \\(x=\\bar x\\). 1.1.1 The summary() function for regression models Before discussing confidence and prediction intervals, let's first revise the output of summary() function for regression models. Recall the model we created the Sugar in Potatoes example, where we try to predict the glucose content of potatoes from the storage time. potatoes &lt;- read.csv(&quot;potatoesstorage.csv&quot;) Model1 &lt;- lm(Glucose ~ Weeks + I(Weeks^2), data=potatoes) We apply the summary function, which gives the following output: summary(Model1) ## ## Call: ## lm(formula = Glucose ~ Weeks + I(Weeks^2), data = potatoes) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.405 -11.250 -8.071 12.911 29.286 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 200.1693 15.0527 13.298 4.02e-08 *** ## Weeks -19.4431 3.1780 -6.118 7.54e-05 *** ## I(Weeks^2) 1.0304 0.1406 7.329 1.49e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 16.4 on 11 degrees of freedom ## Multiple R-squared: 0.8694, Adjusted R-squared: 0.8457 ## F-statistic: 36.61 on 2 and 11 DF, p-value: 1.373e-05 As you can see from this output there are a few different elements displayed. A brief description is stated below: Call: This shows the formula that we used in our regression model. Residuals: This lists the five-number summary of the residuals from our regression model. Coefficients: This shows us a summary of estimated coefficients of the regression model. Within this section the column headers are: Estimate: The estimated parameter. These can be used to write down the fitted regression model. Std. Error: This is the estimated standard error of the parameter estimate. t value: This is the \\(t\\)-statistic for the parameter, calculated as Estimate / Std. Error. Pr(&gt;|t|): This is the \\(p\\)-value that corresponds to the \\(t\\)-statistic, i.e. \\(Pr(X&gt;|t|)\\) for \\(X \\sim t(n-p)\\), where \\(t\\) is the t value computed above, \\(n\\) is the sample size, and \\(p\\) is the number of parameters. Residual standard error: This is the square root of residual mean squares, which can be linked to the output from the anova() table (Residuals Mean Sq). Multiple R-squared: This gives coefficient of determination, \\(R^2\\). Adjusted R-squared: This gives the adjusted coefficient of determination, \\(R^2\\) (adj), which adjusts for the number of predictors in the model. F-statistic: The \\(F\\)-statistic is the test statistic for the hypothesis test H\\(_0\\): all \\(p-1\\) parameters \\(= 0\\) versus H\\(_1\\): at least one parameter \\(\\neq 0\\) p-value: \\(p\\)-value corresponding to the \\(F\\)-test, i.e. \\(Pr(X&gt;|F|)\\) for \\(X \\sim F(\\text{DF}_\\text{model},\\text{DF}_\\text{residual})\\). "],["example-1-cherry-trees.html", "2 Example 1: Cherry trees 2.1 Exploratory analysis 2.2 Statistical analysis", " 2 Example 1: Cherry trees This data set has been looked at in the lectures. The main question of interest is how to model the relationship between log(volume) (\\(y\\)) and log(diameter) (\\(x_1\\)) and log(height) (\\(x_2\\)), using data from 31 cherry trees. To model the relationship we decided to go with the multiple linear regression model \\[\\begin{equation} Y_i = \\alpha + \\beta x_{1i} + \\gamma x_{2i} + \\epsilon_i, \\quad \\epsilon_i \\sim N(0, \\sigma^2), \\quad i=1,\\ldots,31 \\tag{2.1} \\end{equation}\\] 2.1 Exploratory analysis A matrix plot with scatterplots between each pair of variables can be used to gain an initial impression. This can be produced by using the following command in R: trees1 &lt;- read.csv(&quot;trees1.csv&quot;) pairs(trees1, lower.panel = NULL) Figure 2.1: Scatterplot displaying the relationships between the three variables. The argument lower.panel = NULL only displays the top diagonal of the matrix which ensures the response of log(volume) is on the y-axis of the plots. It may be more appropriate to use upper.panel = NULL depending on the position of the response variable in the dataframe. Figure 2.1 shows the relationships between the three variables. DISCUSSION: What can we say about the relationships between the three variables? 2.2 Statistical analysis We now fit the multiple linear regression model in formula (2.1) in R using the following command: Model1 &lt;- lm(logvol ~ logdiam + loght, data = trees1) and produce residual plots to graphically assess the assumptions of the linear model using: plot(rstandard(Model1) ~ fitted(Model1)) abline(h=0, lty=3) qqnorm(rstandard(Model1)) qqline(rstandard(Model1)) Figure 2.2: Residuals vs. fitted values (left) and normal Q-Q plot (right) from model (2.1) fitted to trees. DISCUSSION: Based on the residual plots, comment on whether the assumptions of normal linear models seem to hold or not. 2.2.1 Regression output We can now examine the regression output by typing: summary(Model1) ## ## Call: ## lm(formula = logvol ~ logdiam + loght, data = trees1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.168561 -0.048488 0.002431 0.063637 0.129223 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -6.63162 0.79979 -8.292 5.06e-09 *** ## logdiam 1.98265 0.07501 26.432 &lt; 2e-16 *** ## loght 1.11712 0.20444 5.464 7.81e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.08139 on 28 degrees of freedom ## Multiple R-squared: 0.9777, Adjusted R-squared: 0.9761 ## F-statistic: 613.2 on 2 and 28 DF, p-value: &lt; 2.2e-16 QUESTION: Which of the following comments is most appropriate to describe how well the model fits the data? Based on the R2, 97.77% of the variation in the log volume of the cherry trees is accounted for by the linear model with log diameter and log height as predictors, and hence the model provides a very good fit to the data. Based on the adjusted R2, 97.61% of the variation in the log volume of the cherry trees is accounted for by the linear model with log diameter and log height as predictors, and hence the model provides a very good fit to the data. The p-value for both logdiam and loght are less than 0.05, and hence the model provides a very good fit to the data. The p-value for F-test is less than 0.05, and hence the model provides a very good fit to the data. The analysis of variance (ANOVA) table can also be obtained using: anova(Model1) ## Analysis of Variance Table ## ## Response: logvol ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## logdiam 1 7.9254 7.9254 1196.53 &lt; 2.2e-16 *** ## loght 1 0.1978 0.1978 29.86 7.805e-06 *** ## Residuals 28 0.1855 0.0066 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.2.2 Hypothesis testing The hypotheses being tested for each of the parameters here are: \\[H_0: \\beta = 0 \\ /\\ \\gamma = 0 \\quad \\text{vs.} \\quad H_1: \\beta \\ne 0 \\ / \\ \\gamma \\ne 0\\] Since the \\(p\\)-values for logdiam and loght are both \\(&lt; 0.001\\) (indicated by the significance codes in R '***'), and hence \\(&lt; 0.05\\), the null hypothesis \\(H_0\\) is rejected and we conclude that log(diameter) is a statistically significant predictor of log(volume) in addition to log(height), and log(height) is a statistically significant predictor of log(volume) in addition to log(diameter). 2.2.3 Confidence interval for \\(\\mathbf{b}^\\top \\boldsymbol\\beta\\) From lectures, the formula for a 95% confidence interval for a linear combination of the model parameters is \\[ \\mathbf{b}^\\top\\boldsymbol{\\hat{\\beta}}\\pm t\\left(n-p; 0.975\\right)\\cdot e.s.e(\\mathbf{b}^\\top \\hat{\\boldsymbol\\beta})\\] or, more explicitly, \\[ \\mathbf{b}^\\top\\boldsymbol{\\hat{\\beta}}\\pm t\\left(n-p; 0.975\\right)\\sqrt{\\frac{\\text{RSS}}{n-p}\\mathbf{b}^\\top(\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{b}}\\] A 95% confidence interval for \\(\\beta\\), the coefficient of log(diameter), can be formed by taking the vector \\(\\mathbf{b}\\) to be \\[\\mathbf{b} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}.\\] From the regression output, we know \\(\\hat{\\beta}\\) (the coefficient, estimate of the model parameter) and the estimated standard error for the parameter, which are 1.98265 and 0.07501 respectively. We could also verify the result of estimated standard error. We know that \\[\\text{RSS} = 0.1855 \\quad\\quad\\quad\\quad\\quad n-p = 31 - 3 = 28,\\] and \\((\\mathbf{X}^\\top\\mathbf{X})^{-1}\\) can be computed by using X &lt;- model.matrix(~ logdiam + loght, data = trees1) solve(t(X) %*% X) which gives \\[(\\mathbf{X}^\\top\\mathbf{X})^{-1} = \\begin{bmatrix} 96.572067 &amp; 3.1392672 &amp; -24.165092\\\\ 3.139267 &amp; 0.8494646 &amp; -1.227489\\\\ -24.165092 &amp; -1.2274894 &amp; 6.309851 \\end{bmatrix}\\] Therefore, the estimated standard error for \\(\\beta\\) is given by sqrt(0.1855 / 28 * 0.8494646) ## [1] 0.07501802 To calculate the confidence interval, it remains to find the 0.975th quantile of the \\(t\\)-distribution with 28 degrees of freedom, and we do this in R as follows: qt(p = 0.975, df = 28) ## [1] 2.048407 Calculations Therefore, a 95% confidence interval for \\(\\beta\\) can be found by computing: 1.98265 + 2.048407 * 0.07501 1.98265 - 2.048407 * 0.07501 ## 2.136301 ## 1.828999 Hence a 95% confidence interval for the coefficient of log(diameter) is (1.83, 2.14). As this interval does not contain 0, we conclude that the predictor log(diameter) makes a statistically significant contribution in addition to the predictor log(height) in explaining the variability in log(volume). Therefore log(diameter) is retained in the model, in addition to log(height). The coefficient for log(diameter) is highly likely to lie between 1.83 and 2.14. These intervals can be computed for all estimated parameters simultaneously in using the following command: confint(Model1) ## 2.5 % 97.5 % ## (Intercept) -8.269912 -4.993322 ## logdiam 1.828998 2.136302 ## loght 0.698353 1.535894 QUESTION: Calculate a 95% confidence interval for the coefficient \\(\\gamma\\) using the general formula for a confidence interval; check the result is same as the R output returned from confint(Model1). Interpret this interval. Solution 1.11712 + 2.048407 * 0.20444 1.11712 - 2.048407 * 0.20444 #The estimated standard error is computed as sqrt(0.1855 / 28 * 6.309851) A 95% confidence interval for the coefficient of log(height) is (0.70, 1.54). As this interval does not contain 0, we conclude that the predictor log(height) makes a statistically significant contribution in addition to the predictor log(diameter) in explaining the variability in log(volume). Therefore log(height) is retained in the model, in addition to log(diameter). The coefficient for log(height) is highly likely to lie between 0.70 and 1.54. 2.2.4 Confidence interval for the population mean response and prediction interval for a future response Once we have fitted the model of interest it may also be useful to compute further confidence and prediction intervals from the fitted model. For example, a 95% confidence interval for the population mean response; and a 95% prediction interval for the response of an individual member of the population. Questions Suppose that we consider a population of cherry trees for which the log(diameter) is 2.4 and the log(height) is 4.3. Provide a 95% confidence interval for the mean log(volume) in this population of cherry trees. Interpret the interval. Suppose, now, that we wish to obtain a 95% prediction interval for an individual cherry tree in the population which has a log(diameter) of 2.4 and a log(height) of 4.3. Interpret the interval. We use R to compute the required intervals. Question 1 - 95% confidence interval for the population mean: predframe &lt;- data.frame(logdiam = 2.4, loght = 4.3) predict(Model1, int = &quot;c&quot;, newdata = predframe) ## fit lwr upr ## 1 2.930373 2.894059 2.966686 The data.frame command creates a table; each column represents one variable and each row contains one set of values from each column. The predict command can produce both a confidence interval and a prediction interval. To obtain a confidence interval we use the argument int = \"c\". Therefore we conclude that in a population of cherry trees for which the log(diameter) is 2.4 and the log(height) is 4.3 it is highly likely that the log(volume) would lie, on average, somewhere between 2.89 and 2.97. Question 2 - 95% prediction interval for a future tree: predict(Model1, int = &quot;p&quot;, newdata = predframe) ## fit lwr upr ## 1 2.930373 2.759752 3.100994 The argument int = \"p\" in the predict command provides a prediction interval based on the specified values in the new dataframe predframe. Therefore if a cherry tree with a log(diameter) of 2.4 and a log(height) of 4.3 were selected randomly from the population of cherry trees, it is highly likely that it would have a log volume of somewhere between 2.76 and 3.10. Comparing with the 95% confidence interval, the 95% prediction interval has a wider range. "],["exercise-1-grades.html", "3 Exercise 1: Grades", " 3 Exercise 1: Grades In Lab 1, we looked at the Grades dataset from the PASWR package, which records the first-semester college GPA and SAT scores for 200 freshmen. The question of interest is to check whether there is a linear relationship between GPA and SAT scores. To open the dataset, type: library(PASWR) GRADES &lt;- Grades QUESTION Fit the simple linear regression model on this data again and check if the model assumptions hold true. Solution Model2 &lt;- lm(gpa~sat, data=GRADES) plot(rstandard(Model2) ~ fitted(Model2)) abline(h=0, lty=3) qqnorm(rstandard(Model2)) qqline(rstandard(Model2)) In the standardised residuals versus fitted values plot, we see that the points are fairly evenly scattered above and below the zero line, which suggests it is reasonable to assume that the random errors have mean zero. The vertical variation of the points seems to be small for small and large fitted values and large for fitted values in the middle. This raises slight concerns on constant variability, though we should also take into account that there are less observations in both ends. The normal probability plot (Q-Q plot) suggests that points roughly lie on diagonal line, though there is some deviation at the extremes. We may conclude that the normality assumption holds with some caution. Which of the following comments on the adequacy of the model seems appropriate? Based on R2, 56.12% of the variation in GPA scores is accounted for by the simple linear regression model with SAT scores as the predictor, and hence the model provides a moderate fit to the data. Based on adjusted R2, 55.89% of the variation in GPA scores is accounted for by the simple linear regression model with SAT scores as the predictor, and hence the model provides a moderate fit to the data. 3. Without using the summary() command, calculate the values of A and B in the following regression output table. Estimate Std. Error t value (Intercept) -1.192 0.22245 A sat 0.003 B 15.912 A = B = 4. Construct a 95% confidence interval for the coefficient of sat. Comment on the interval. Solution We could either calculate manually based on the output from summary() or use confint(). summary(Model2) 0.0030943 + qt(0.975,200-2)*0.0001945 0.0030943 - qt(0.975,200-2)*0.0001945 confint(Model2) The 95% confidence interval for the coefficient of sat is (0.0027,0.0035), indicating that the SAT scores makes a statistically significant contribution in explaining the GPA scores. 5. Which of the following comments on the \\(p\\)-value for the predictor sat is appropriate? The \\(p\\)-value is less than 0.05, so we reject the null hypothesis that the coefficient for SAT equals to zero and conclude that SAT is useful in predicting GPA scores. The \\(p\\)-value is less than 0.05, so we fail to reject the null hypothesis that the coefficient for SAT equals to zero and conclude that SAT is not useful in predicting GPA scores. The \\(p\\)-value is larger than 0.05, so we reject the null hypothesis that the coefficient for SAT equals to zero and conclude that SAT is useful in predicting GPA scores. The \\(p\\)-value is larger than 0.05, so we fail to reject the null hypothesis that the coefficient for SAT equals to zero and conclude that SAT is not useful in predicting GPA scores. "],["exercise-2-body-fat.html", "4 Exercise 2: Body fat", " 4 Exercise 2: Body fat The dataset femalebodyfat.csv gives the % body fat, triceps skinfold thickness (taken at the midpoint of the upperarm) and the midarm circumference (the circumference of the non-dominant arm midway between the shoulder and the elbow) for twenty healthy females aged 20 to 34. The % body fat for each person was obtained by a cumbersome and expensive procedure requiring the immersion of the person in water. It would therefore be very helpful if a regression model with tricep skinfold thickness and midarm circumference could provide reliable predictions of the amount of body fat, since the measurements needed for the predictor variables are straightforward to obtain. Read in the data using: bf &lt;- read.csv(&quot;femalebodyfat.csv&quot;) QUESTION Use an appropriate exploratory analysis to explore the relationships between % body fat, triceps skinfold thickness and midarm circumference. Solution pairs(bf, lower.panel = NULL) This shows a moderate positive linear relationship between % body fat and triceps skinfold thickness. There doesn't seem to be much of a relationship between % body fat and midarm circumference but we will continue to explore whether it is useful to the model. Fit a multiple linear regression model to the data in order to predict % body fat from triceps skinfold thickness and midarm circumference. Provide very brief comments on the adequacy of your model. Solution modelfat &lt;- lm(Fat ~ Triceps + Midarm, data=bf) Use R to compute a 95% confidence interval for the coefficient of each predictor in the model. Solution confint(modelfat) ## 2.5 % 97.5 % ## (Intercept) -2.67783060 16.261085426 ## Triceps 0.73003885 1.271130967 ## Midarm -0.08040683 -0.005881575 Comment on your intervals. The confidence interval for the variable Triceps contain zerodoes not contain zero so we conclude it makesdoes not make a statistically significant contribution in addition to the predictor Midarm in explaining the variability in Fat. Therefore Triceps should be retained inremoved from the model. The coefficient for Triceps is highly likely to lie between and (Enter your answer by rounding to two decimal places). Find a 95% confidence interval for the mean % body fat for a female (aged 20 to 34) whose triceps skinfold thickness is 25mm and midarm circumference is 310mm. Interpret the interval. Hint Define the prediction dataframe for the given predictor values and use the predict() function with that dataframe. Be careful to use the correct parameter to get a confidence interval not a prediction interval. Solution predframe &lt;- data.frame(Triceps = 25, Midarm = 310) predict(modelfat, int = &quot;c&quot;, newdata = predframe) ## fit lwr upr ## 1 18.43155 16.67794 20.18516 Find a 95% prediction interval for the % body fat of a future female with skinfold thickness and midarm circumference values of your choice. Interpret the interval. Solution predframe &lt;- data.frame(Triceps = 20, Midarm = 250) predict(modelfat, int = \"p\", newdata = predframe) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
